<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta property="og:image" content="images/IMG_4350.jpg" />
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://www.allenkcheung.com/" /> 
    <meta property="og:title" content="Allen Cheung" />
    <meta property="og:description" content="Welcome to Allen Cheung's personal website. Thank you for visiting!" />

    <title>Allen Cheung</title>
    <link rel="icon" type="image/x-icon" href="images/favicon.png">
    <link rel="stylesheet" href="style.css?v=6">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css"/>
    <script src="https://code.jquery.com/jquery-3.5.1.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/typed.js/2.0.11/typed.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/waypoints/4.0.1/jquery.waypoints.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/OwlCarousel2/2.3.4/owl.carousel.min.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/OwlCarousel2/2.3.4/assets/owl.carousel.min.css"/>
</head>
<body>
    <div class="scroll-up-btn">
        <i class="fas fa-angle-up"></i>
    </div>
    <nav class="navbar">
        <img src = "images/IMG_4350.jpg" alt="" style="display:none">
        <div class="max-width">
            <div class="logo"><a href="#">allen<span> cheung</span></a></div>
            <ul class="menu">
                <li><a href="#about" class="menu-btn">about</a></li>
                <li><a href="#projects" class="menu-btn">projects</a></li>
                <li><a href="#experience" class="menu-btn">experience</a></li>
                <li><a href="#art" class="menu-btn">art</a></li>
                <li><a href="#contact" class="menu-btn">contact</a></li>
            </ul>
            <div class="menu-btn">
                <i class="fas fa-bars"></i>
            </div>
        </div>
        <div class="progress-bar" id="myBar"></div>
    </nav>

    <section class="about" id="about">
        <div class="max-width">
            <div class="about-content">
                <div class="column left">
                    <img src="images/profile-1.jpeg" alt="">
                </div>
                <div class="column right">
                    <div class="text-1">Hello, I'm <span class = 'typing'></span></div>
                    <div class="body">
                        <p>I am a senior Computer Science student at <a href="https://www.ucsd.edu">UC San Diego</a>, and will be graduating in <span style="font-weight: 500">June 2022</span>. Following my graduation, I will be attending graduate school at <a href = "https://www.ucla.edu/">UCLA</a> in pursuit of a <span style="font-weight: 500">Master of Science</span> in Computer Science with a concentration in  <span style="font-weight: 500">Artificial Intelligence</span>.</p>
                        <p>My interests lie in <span style="font-weight: 500">computer vision</span> and multidisciplinary <span style="font-weight: 500">deep learning</span> applications. I am currently seeking internship opportunities for   <span style="font-weight: 500">Summer 2022</span>.</p>
                        <p><span style="font-size: 30px" >&#128205;</span> <span id = "sj">San Jose, CA</span><span id = "email">&#9993;&#65039;</span>akcheung @ ucsd.edu </p>
                    </div>
                    <a href="https://www.linkedin.com/in/akcheung/" id = "linkedin"><img src = images/linkedin.svg width=17px>  LinkedIn</a>
                    <a href="https://github.com/akcheu/" id = "github"><img src = images/githubs.svg width = 18px>  GitHub</a>
                    <a href="https://drive.google.com/file/d/1qZPQ-ffZnP-pCrhx_FWuxFGcZmWaZVoc/view?usp=sharing" id = "resume"><img src = images/resume.png width = 18px>  Resume</a>
                </div>
            </div>
        </div>
    </section>

    <section class="projects" id="projects">
        <div class="max-width">
            <div class="title" id = "hideme">
                <div class="title-text">Projects</div>
            </div>
            <div class = proj-header-first id = "hideme">
                <div class = "proj-title-container">
                    <div class = "proj-title-first"><span class = "emoji">&#128663;</span>2D-3D Multi-modal fusion for AVs</div>
                    <div class = "tag-container">
                        <div class = "tag" style = "background: rgb(173, 220, 173)"><span style = "color: rgb(80, 125, 80)">Vision</span></div>
                        <div class = "tag" style = "background: rgb(212, 190, 249);"><span style = "color:rgb(108, 86, 145)">Learning</span></div>
                    </div>
                </div>
                <div class = "desc-header"><span>AUG 2021 - NOW</span><a href="http://www.svcl.ucsd.edu/~nuno/"> @ SVCL</a></div>
            </div>
            <div class = "card-container" id = "hideme">
                <div class = "info">
                    <iframe src="https://docs.google.com/presentation/d/e/2PACX-1vRp0uip8tKQM962RNH6zq6iC_9iIYgYzUkQG7w7dhJBNMcXRhDZ9Arame0X-J9YeICzLE3w-b_fsy9X/embed?start=true&loop=true&delayms=5000" frameborder="0" width=647 height="400" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>
                </div>
                <div class = "desc">
                    <p>In this project, we are leveraging <a href = "https://arxiv.org/pdf/1506.01497.pdf" class = "desc-link">Faster R-CNN </a> and multimodal fusion mechanisms (<a href = "https://arxiv.org/pdf/1904.01649.pdf" class = "desc-link">MVX-Net</a>) to develop a deep learning model that fuses <span style="font-weight:600">2D images</span> and <span style="font-weight:600">3D point clouds</span> to improve autonomous driving action explainability & navigation. Prior work by <a href = ‚Äúhttps://arxiv.org/pdf/2003.09405.pdf‚Äù class = "desc-link">Xu et. al</a> has demonstrated that multi-task learning improves 2D object detection and provides intuitive explanations for actions performed by an AV. We are aiming to extend upon this work to incorporate the 3D modality in hopes of improving performance in scenarios such as <span style="font-weight:600">bad weather</span> or <span style="font-weight:600">night</span> where the 2D image modality may fail. To gather data, I designed an Amazon MTurk data annotation interface to collect labels on the <a href = ‚Äúhttps://waymo.com/intl/en_us/open/about/‚Äú class = "desc-link"> Waymo Open </a> dataset for driver actions and explanations.</p>
                    <a href = "http://www.allenkcheung.com/mturk-interface/" class = "interface-button" style = "font-weight: 300;background-color: none; color: rgb(112, 166, 196);">Try the annotation interface!</a>
                </div>
            </div>

            <div class = proj-header id = "hideme" style = "padding-top: 100px;">
                <div class = "proj-title-container">
                    <div class = "proj-title"><span class = "emoji">&#128038;</span>Unsupervised 3D Reconstruction</div>
                    <div class = "tag-container">
                        <div class = "tag" style = "background: rgb(173, 220, 173)"><span style = "color: rgb(80, 125, 80)">Vision</span></div>
                        <div class = "tag" style = "background: rgb(212, 190, 249);"><span style = "color:rgb(108, 86, 145)">Learning</span></div>
                    </div>
                </div>
                <div class = "desc-header"><span>FEB - AUG 2021</span><a href="http://www.svcl.ucsd.edu/~nuno/"> @ SVCL</a></div>
            </div>
            <div class = "card-container" id = "hideme">
                <div class = "info">
                    <div class = "image" style="display:flex; flex-direction:column;">
                        <img src = "images/seagull.gif" style="width: 195px">
                        <img src = "images/shadow.png" style="width:195px; margin-top: -55px; opacity:50%; margin-right: 15px; margin-bottom: 15px">
                    </div>
                    <div class = "image" style="display:flex; flex-direction:column;">
                        <img src = "images/truck.gif" style="width: 195px">
                        <img src = "images/shadow.png" style="width:195px; margin-top: -55px; opacity: 50%;  margin-right: 15px">
                    </div>
                    <div class = "image" style="display:flex; flex-direction:column;">
                        <img src = "images/wagon.gif" style="width: 195px">
                        <img src = "images/shadow.png" style="width:195px; margin-top: -55px; opacity: 50%;  margin-right: 15px">
                    </div>
                    <div class = "image" style="display:flex; flex-direction:column;">
                        <img src = "images/seagull_orig.png" style="width: 195px; height: 140px;border-radius: 15px;  margin-right: 15px; margin-left: 15px;">
                    </div>
                    <div class = "image" style="display:flex; flex-direction:column;">
                        <img src = "images/truck_orig.png" style="width: 195px; height: 140px; border-radius: 15px;  margin-right: 15px">
                    </div>
                    <div class = "image" style="display:flex; flex-direction:column;">
                        <img src = "images/wagon.png" style="width: 195px; height: 140px; border-radius: 15px;  margin-right: 15px">
                    </div>
                </div>
                <div class = "desc">
                    <p>Fully supervised methods [1, 2, 4] relied on unreasonably large amounts of synthetic data, while current unsupervised methods [5, 6, 7] are clearly lacking in performance. We wanted to explore how we can incorporate a small amount of 3D data in this latter group to boost this suboptimal performance. This would potentially be especially useful for classes with complex topologies or different modes, such as pianos, cups, or chairs.¬†We selected the paper Shape and Viewpoints without Keypoints (UCMR) [5] as the base of our work. Our first step was to verify our hypothesis that the mean template shape greatly affected performance, and thus incorporating a more suitable base shape to the specific class mode would lead to improvements.</p>
                </div>
            </div>
            <div class = proj-header id = "hideme" style="margin-top: -20px">
                <div class = "proj-title-container">
                    <div class = "proj-title"><span class = "emoji">&#129514;</span>SMART 5.0</div>
                    <div class = "tag-container">
                        <div class = "tag" style = "background: rgb(212, 190, 249);"><span style = "color:rgb(108, 86, 145)">Learning</span></div>
                        <div class = "tag" style = "background: rgb(154, 200, 250)"><span style = "color: rgb(59, 118, 181)">Chemistry</span></div>

                    </div>
                </div>
                <div class = "desc-header"><span>MAR 2021 - NOW</span><a href="https://cseweb.ucsd.edu/groups/guru/"> @ GURU</a></div>
            </div>
            <div class = "card-container" id = "hideme">
                <div class = "info">
                    <iframe src="https://drive.google.com/file/d/1wi4KchkbJNMJ_gpN8Yb7Ms_S0bEJR2XF/preview" width="655" height="480"></iframe>
                </div>
                <div class = "desc">
                    <p>SMART 5.0 is a deep learning model that uses a Transformer architecture for natural product identification in the drug discovery workflow. Previous iterations of SMART adopted a CNN-based architecture, taking in images of HSQC spectra plots as input to the model. Given the sequential nature of HSQC spectra coordinates, Morgan Fingerprints, and SMILES strings, a sequence-to-sequence Transformer model may be better suited for the problem. </p>
                </div>
            </div>
            <div class = proj-header id = "hideme" style="padding-top: 150px">
                <div class = "proj-title-container">
                    <div class = "proj-title"><span class = "emoji">&#128444;&#65039;</span>Basic 3D Image Reconstruction</div>
                    <div class = "tag-container">
                        <div class = "tag" style = "background: rgb(173, 220, 173)"><span style = "color: rgb(80, 125, 80)">Vision</span></div>
                        <div class = "tag" style = "background: rgb(212, 190, 249);"><span style = "color:rgb(108, 86, 145)">Learning</span></div>
                    </div>
                </div>
                <div class = "desc-header"><span>DEC 2021</span><a href="http://www.svcl.ucsd.edu/~nuno/"> @ CSE 152A</a></div>
            </div>
            <div class = "card-container" id = "hideme" style="height:500">
                <div class = "info" style="display: flex; flex-direction: column; height: 580px;">
                    <img src = "images/bird_temp.png" style="width: 640px; margin-bottom: 15px; border-radius: 15px;">
                    <img src = "images/3dbird.png" style="width: 640px; border-radius: 15px;">
                </div>
                <div class = "desc">
                    <p>In the domain of computer vision, point cloud data allows for objects to be represented in the three dimensional space through a large set of (ùë•, ùë¶, ùëß) geometric coordinates. This project uses a dataset of 49 images of a bird plushie on a platform from various perspectives to reconstruct a 3D point-cloud representation of the object. I approached this problem through the means of multi-view stereo (MVS) by drawing point correspondences between neighboring stereo images, leveraging triangulation to reconstruct a set of 3D points, and ultimately validating the resulting point cloud for outliers to remove noise. Prior to deriving point correspondences, I utilized the Scale Invariant Feature Transform (SIFT) detection algorithm in the OpenCV library to identify points of interests across the 49 images.</p>
                </div>
            </div>
            <div class = proj-header id = "hideme">
                <div class = "proj-title-container">
                    <div class = "proj-title"><span class = "emoji">&#128101;</span>Shadow Mapping</div>
                    <div class = "tag-container">
                        <div class = "tag" style = "background: rgb(250, 200, 200)"><span style = "color: rgb(184, 110, 110)">Graphics</span></div>
                    </div>
                </div>
                <div class = "desc-header"><span>NOV 2021</span><a href="http://www.svcl.ucsd.edu/~nuno/"> @ CSE 167</a></div>
            </div>
            <div class = "card-container" id = "hideme">
                <div class = "info" >
                    <iframe src="http://www.youtube.com/embed/RxEcCIRT5G0?rel=0&modestbranding=1&autohide=1&mute=1&showinfo=0&controls=0&autoplay=1"  width="660" height="366"  frameborder="0" allowfullscreen></iframe>
                </div>
                <div class = "desc">
                    <p>Shadow mapping is a common technique for the creation of hard shadows in a scene rendering of objects with the help of texture buffers. For this project, I experimented with shadow mapping by employing two rendering passes to create the effect: one is a camera at the light source responsible for casting the light and shadows, and another is at the actual camera that is considered for the viewer‚Äôs perspective.</p>
                </div>
            </div>
            <div class = proj-header id = "hideme" style="margin-top: -25px">
                <div class = "proj-title-container">
                    <div class = "proj-title"><span class = "emoji">&#128172;</span>Hate Speech Classifier</div>
                    <div class = "tag-container">
                        <div class = "tag" style = "background: rgb(238, 194, 118)"><span style = "color: rgb(174, 136, 71)">NLP</span></div>
                        <div class = "tag" style = "background: rgb(212, 190, 249);"><span style = "color:rgb(108, 86, 145)">Learning</span></div>
                    </div>
                </div>
                <div class = "desc-header"><span>MAR 2022</span><a href="http://www.svcl.ucsd.edu/~nuno/"> @ LIGN 167</a></div>
            </div>
            <div class = "card-container" id = "hideme">
                <div class = "info">
                    <iframe src="https://drive.google.com/file/d/1IaKxtMusPcdF7RddTJJo3dcpyXJLs43W/preview" width="655" height="480"></iframe>
                </div>
                <div class = "desc">
                    <p>In this project, we aim to employ domain specific pre-training to improve results on the downstream task of hate speech classification. We fine-tune a BERT language model to perform binary and multi-class classification on the Twitter [1], Reddit [3] , and Gab [3] datasets as a baseline for our experiment. Then, we pretrain a BERT model on a large corpus of 636K hate speech entries using the Parler [5] dataset. Our pre-trained model Parler5 achieved a highest MCC score of 0.592 on the Twitter dataset, marginally outperforming our baseline model by 1.2%.</p>
                </div>
            </div>
        </div>
    </section>

    <section class="experience" id="experience">
        <div class="max-width">
            <div class="title" style = "width: 225px; background: rgb(225, 211, 186)">
                <div class="title-text">Experience</div>
            </div>
        </div>
    </section>

    <section class="art" id="art">
        <div class="max-width">
            <div class="title">
                <div class="title-text">Artwork</div>
            </div>
            <div class="grid-wrapper">
                <div class = "tall" id = "hideme">
                    <img src="images/IMG_0968.jpg" alt="" />
                </div>
                <div class = "tall" id = "hideme">
                    <img src="images/IMG_0981.jpg" alt="" />
                </div>
                <div class = "tall" id = "hideme">
                    <img src="images/IMG_0980.jpg" alt="" />
                </div>
                <div class = "" id = "hideme">
                    <img src="images/IMG_1484.jpg" alt="" />
                </div>
                <div class = "big" id = "hideme">
                    <img src="images/IMG_1981.jpg" alt="" />
                </div>
                <div class = "tall" id = "hideme">
                    <img src="images/IMG_0969.jpg" alt="" />
                </div>
                <div class = "tall" id = "hideme">
                    <img src="images/IMG_0986.jpg" alt="" />
                </div>
                <div class = "big" id = "hideme">
                    <img src="images/blue.png" alt="" />
                </div>
                <div class = "tall" id = "hideme">
                    <img src="images/IMG_0971.jpg" alt="" />
                </div>
                <div class = "tall" id = "hideme">
                    <img src="images/IMG_0982.jpg" alt="" />
                </div>
                <div class = "tall" id = "hideme">
                    <img src="images/IMG_0983.jpg" alt="" />
                </div>
                <div class = "big" id = "hideme">
                    <img src="images/IMG_3530 3.PNG" alt="" />
                </div>
                <div class ="tall" id = "hideme">
                    <img src="images/IMG_0984.jpg" alt="" />
                </div>
                <div class = "tall" id = "hideme">
                    <img src="images/IMG_0987.jpg" alt="" />
                </div>
            </div>
        </div>
    </section>

    <footer>
        <span>Created By <a href="https://akcheu.github.io/">Allen</a> | <span class="far fa-copyright"></span> 2022 All rights reserved.</span>
    </footer>

    <script src="script.js?v=5"></script>
</body>
</html>
